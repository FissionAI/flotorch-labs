{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9e58641-fd5a-4b88-b07d-f187aba9676b",
   "metadata": {},
   "source": [
    "# FloTorch\n",
    "\n",
    "**FloTorch** is an open-source tool designed to streamline and optimize Generative AI workloads on AWS.  \n",
    "It automates the development of Retrieval-Augmented Generation (RAG) proof-of-concepts with features like hyperparameter tuning, vector database optimization, and LLM integration. FloTorch facilitates experimentation, ensures security, and accelerates production with cost-efficient, validated workflows.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¬ Demo Video\n",
    "\n",
    "ðŸ‘‰ Watch a quick demo of FloTorch in action:\n",
    "\n",
    "[![FloTorch Demo](https://img.youtube.com/vi/00000000000/0.jpg)](https://fissiontorch-public.s3.us-east-1.amazonaws.com/demo.mp4)\n",
    "\n",
    "> Or open directly: [https://fissiontorch-public.s3.us-east-1.amazonaws.com/demo.mp4](https://fissiontorch-public.s3.us-east-1.amazonaws.com/demo.mp4)\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ Key Features\n",
    "\n",
    "- **Automated RAG Optimization**: Automatically fine-tune RAG pipelines for specific use cases, reducing time-to-market.\n",
    "- **LLMOps & FMOps Optimization**: Streamline the AI lifecycle from model management to operational efficiency.\n",
    "- **Enterprise Monitoring**: Get real-time monitoring for enterprise-scale GenAI applications.\n",
    "- **Observability & Traceability**: Maintain full auditability and transparency.\n",
    "- **Secure AWS Deployment**: All data and operations stay within your AWS account.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1b27d6-f5c6-4f2b-a27d-79c68e61c7b5",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "\n",
    "1. Prepare documents to be used in Amazon Bedrock Knowledge Base.\n",
    "2. Add metadata to the input documents for advanced query features (covered in Lab2).\n",
    "3. Create required AWS resources to run the Bedrock Knowledge Base service.\n",
    "4. Create an Amazon OpenSearch Service collection as a vector store."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dca54a5-0a31-493b-95d7-e14996bfa49b",
   "metadata": {},
   "source": [
    "### 1. Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "020dd9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "52ef8169-6ec6-4cf2-acca-b722e377b69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'flotorch-core'...\n",
      "remote: Enumerating objects: 1699, done.\u001b[K\n",
      "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
      "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
      "remote: Total 1699 (delta 25), reused 32 (delta 19), pack-reused 1653 (from 2)\u001b[K\n",
      "Receiving objects: 100% (1699/1699), 12.38 MiB | 5.46 MiB/s, done.\n",
      "Resolving deltas: 100% (880/880), done.\n"
     ]
    }
   ],
   "source": [
    "# Clone flotroch repo\n",
    "!git clone git@github.com:FissionAI/flotorch-core.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ac72e6ad-1197-4285-9014-102be3f351f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv ./flotorch-core/flotorch_core flotorch_core\n",
    "!rm -rf flotorch-core\n",
    "!cp custom_eval.py flotorch_core/evaluator/custom_eval.py\n",
    "!cp mistal.py flotorch_core/evaluator/mistal.py\n",
    "!cp system_prompt.txt flotorch_core/evaluator/system_prompt.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79bc56f9-c071-4b62-820c-46aa8ecfd5f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages (1.36.2)\n",
      "Collecting boto3\n",
      "  Using cached boto3-1.37.32-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: opensearch-py in /Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages (2.8.0)\n",
      "Collecting botocore<1.38.0,>=1.37.32 (from boto3)\n",
      "  Using cached botocore-1.37.32-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages (from boto3) (0.11.3)\n",
      "Requirement already satisfied: urllib3!=2.2.0,!=2.2.1,<3,>=1.26.19 in /Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages (from opensearch-py) (2.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.0 in /Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages (from opensearch-py) (2.32.3)\n",
      "Requirement already satisfied: python-dateutil in /Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages (from opensearch-py) (2.9.0.post0)\n",
      "Requirement already satisfied: certifi>=2024.07.04 in /Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages (from opensearch-py) (2024.12.14)\n",
      "Requirement already satisfied: Events in /Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages (from opensearch-py) (0.5)\n",
      "Requirement already satisfied: six>=1.5 in /Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages (from python-dateutil->opensearch-py) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages (from requests<3.0.0,>=2.32.0->opensearch-py) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages (from requests<3.0.0,>=2.32.0->opensearch-py) (3.10)\n",
      "Using cached boto3-1.37.32-py3-none-any.whl (139 kB)\n",
      "Using cached botocore-1.37.32-py3-none-any.whl (13.5 MB)\n",
      "Installing collected packages: botocore, boto3\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.36.26\n",
      "    Uninstalling botocore-1.36.26:\n",
      "      Successfully uninstalled botocore-1.36.26\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.36.2\n",
      "    Uninstalling boto3-1.36.2:\n",
      "      Successfully uninstalled boto3-1.36.2\n",
      "Successfully installed boto3-1.37.32 botocore-1.37.32\n"
     ]
    }
   ],
   "source": [
    "# Update python packages\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1268baf2-ed49-4f96-bd3e-6f7c6f4fd2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS Account: 677276078734\n",
      "Role ARN: arn:aws:iam::677276078734:user/ravi.tiruvedula@fissionlabs.com\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "\n",
    "# Initialize Boto3 session\n",
    "boto3_session = boto3.session.Session()\n",
    "credentials = boto3_session.get_credentials()\n",
    "region_name = \"us-east-1\"\n",
    "\n",
    "# Retrieve AWS account details\n",
    "sts_client = boto3_session.client(\"sts\")\n",
    "account_number = sts_client.get_caller_identity()[\"Account\"]\n",
    "role_arn = sts_client.get_caller_identity()[\"Arn\"]\n",
    "\n",
    "# Set up authentication for OpenSearch\n",
    "awsauth = AWSV4SignerAuth(credentials, region_name, \"aoss\")\n",
    "\n",
    "# Print account details for verification\n",
    "print(f\"AWS Account: {account_number}\")\n",
    "print(f\"Role ARN: {role_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc15787e-c2c3-4d48-bc59-37aff4dcb017",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Bucket Name: 677276078734-us-east-1-advanced-rag-workshop\n",
      "OpenSearch Vector Store Name: advancedrag\n",
      "OpenSearch Index Name Prefix: ws-index-\n"
     ]
    }
   ],
   "source": [
    "# Resource names to be used in the workshop\n",
    "\n",
    "s3_bucket_name = f\"{account_number}-{region_name}-advanced-rag-workshop\"\n",
    "# knowledge_base_name_aoss = \"advanced-rag-workshop-knowledgebase-aoss\"\n",
    "# knowledge_base_name_graphrag = \"advanced-rag-workshop-knowledgebase-graphrag\"\n",
    "\n",
    "oss_vector_store_name = \"advancedrag\"\n",
    "oss_index_name = \"ws-index-\"\n",
    "\n",
    "# Print resource names for verification\n",
    "print(f\"S3 Bucket Name: {s3_bucket_name}\")\n",
    "# print(f\"Knowledge Base (AOSS): {knowledge_base_name_aoss}\")\n",
    "# print(f\"Knowledge Base (GraphRAG): {knowledge_base_name_graphrag}\")\n",
    "print(f\"OpenSearch Vector Store Name: {oss_vector_store_name}\")\n",
    "print(f\"OpenSearch Index Name Prefix: {oss_index_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cc22f1-4cd7-4ba3-b65c-2b4e4769c89f",
   "metadata": {},
   "source": [
    "### 2. Create required AWS resources "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11565dc-2a2c-43b4-8c88-1b5c20cc8f5a",
   "metadata": {},
   "source": [
    "#### IAM Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9e49512-7872-4610-a990-554b8fd5a043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred (EntityAlreadyExists) when calling the CreatePolicy operation: A policy called advanced-rag-fm-policy-us-east-1 already exists. Duplicate names are not allowed.\n",
      "Policies already exist. Please clean them up first.\n",
      "WARNING: Could not determine the Bedrock KB execution role ARN.\n"
     ]
    }
   ],
   "source": [
    "from prerequisites.bedrock_excution_iam_role import AdvancedRagIamRoles\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Initialize IAM role handler\n",
    "bedrock_execution_iam_role = AdvancedRagIamRoles(account_number, region_name)\n",
    "\n",
    "# Check if the role already exists\n",
    "iam_client = boto3.client(\"iam\", region_name=region_name)\n",
    "role_name = f\"advanced-rag-workshop-bedrock_execution_role1-{region_name}\"\n",
    "bedrock_kb_execution_role_arn = \"\"\n",
    "\n",
    "try:\n",
    "    # Try to get the existing role\n",
    "    existing_role = iam_client.get_role(RoleName=role_name)\n",
    "    bedrock_kb_execution_role_arn = existing_role[\"Role\"][\"Arn\"]\n",
    "    # print(bedrock_kb_execution_role_arn)\n",
    "    print(f\"Policy and roles have been created already. ARN: {bedrock_kb_execution_role_arn}\")\n",
    "except Exception as e:\n",
    "    if e.response[\"Error\"][\"Code\"] == \"NoSuchEntity\":\n",
    "        try:\n",
    "            # Role does not exist, create it\n",
    "            bedrock_kb_execution_role = bedrock_execution_iam_role.create_bedrock_execution_role(s3_bucket_name)\n",
    "            bedrock_kb_execution_role_arn = bedrock_kb_execution_role[\"Role\"][\"Arn\"]\n",
    "            print(f\"Created Bedrock Knowledge Base Execution Role ARN: {bedrock_kb_execution_role_arn}\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Policies already exist. Please clean them up first.\")\n",
    "    else:\n",
    "        # Handle other client errors\n",
    "        print(\"Policy and roles have been created already.\")\n",
    "\n",
    "if not bedrock_kb_execution_role_arn:\n",
    "    print(\"WARNING: Could not determine the Bedrock KB execution role ARN.\")\n",
    "    bedrock_kb_execution_role_arn = f\"arn:aws:iam::{account_number}:role/{role_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f48397-af48-4cb0-81b0-7e4fd7f535aa",
   "metadata": {},
   "source": [
    "#### S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b53de93-f6b9-4835-807c-eaf7dd772ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677276078734-us-east-1-advanced-rag-workshop\n",
      "<botocore.client.S3 object at 0x13b6ac880>\n",
      "us-east-1\n",
      "Bucket '677276078734-us-east-1-advanced-rag-workshop' already exists.\n"
     ]
    }
   ],
   "source": [
    "# Initialize S3 client with the specified AWS region\n",
    "s3 = boto3.client(\"s3\", region_name=region_name)\n",
    "print(s3_bucket_name)\n",
    "print(s3)\n",
    "print(region_name)\n",
    "try:\n",
    "    # Check if the S3 bucket already exists\n",
    "    s3.head_bucket(Bucket=s3_bucket_name)\n",
    "    print(f\"Bucket '{s3_bucket_name}' already exists.\")\n",
    "except:\n",
    "    # Create the S3 bucket if it does not exist\n",
    "    s3.create_bucket(Bucket=s3_bucket_name)\n",
    "    print(f\"Bucket '{s3_bucket_name}' created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74286f9e-eee6-45c5-941c-ac4271ada540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to upload all files from a local directory to an S3 bucket\n",
    "def upload_directory(path, bucket_name, data_s3_prefix):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            key = f\"{data_s3_prefix}/{file}\"  # Construct the S3 object key\n",
    "            s3.upload_file(os.path.join(root, file), bucket_name, key)  # Upload the file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2624af69-c171-478f-a1be-3bce4c32aefb",
   "metadata": {},
   "source": [
    "### 3. Preparing Data Sources with .metadata.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caef98c-b9c6-40a6-9dfa-c0ab2984f55c",
   "metadata": {},
   "source": [
    "### Role of Metadata While Indexing Data in Vector Databases  \n",
    "\n",
    "Metadata provides additional context and information about the documents, which can be used to filter, sort, and improve search accuracy. This not only helps reduce the search latency but also helps increase accuracy of responses.  \n",
    "\n",
    "The following are some key uses of metadata when loading documents into a vector data store:  \n",
    "\n",
    "- **Document Identification** â€“ Metadata can include unique identifiers for each document, such as document IDs, URLs, or file names. These identifiers can be used to uniquely reference and retrieve specific documents from the vector data store.  \n",
    "- **Content Categorization** â€“ Metadata can provide information about the content or category of a document, such as the subject matter, domain, or topic. This information can be used to organize and filter documents based on specific categories or domains.  \n",
    "- **Document Attributes** â€“ Metadata can store additional attributes related to the document, such as the author, publication date, language, or any other relevant information. These attributes can be used for filtering, sorting, or faceted search within the vector data store.  \n",
    "- **Access Control** â€“ Metadata can include information about access permissions or security levels associated with a document. This information can be used to control access to sensitive or restricted documents within the vector data store.  \n",
    "- **Relevance Scoring** â€“ Metadata can be used to enhance the relevance scoring of search results. For example, if a user searches for documents within a specific date range or authored by a particular individual, the metadata can be used to prioritize and rank the most relevant documents.  \n",
    "- **Data Enrichment** â€“ Metadata can be used to enrich the vector representations of documents by incorporating additional contextual information. This can potentially improve the accuracy and quality of search results.  \n",
    "- **Data Lineage and Auditing** â€“ Metadata can provide information about the provenance and lineage of documents, such as the source system, data ingestion pipeline, or any transformations applied to the data. This information can be valuable for data governance, auditing, and compliance purposes.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f0ca6f-68c8-40c9-bbef-75aa0fd4dc48",
   "metadata": {},
   "source": [
    "#### 3.1 Unstructured (PDF) document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd13c19-f890-4392-bf8d-fd7221f86346",
   "metadata": {},
   "source": [
    "#### Amazon Science papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c933b1e9-74b4-4061-921a-7cc60c909d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define URLs of Amazon Science Publications to download as example documents\n",
    "urls = [\n",
    "    \"https://assets.amazon.science/44/ba/e16182124eac8687e89d3cb0ea3d/retrieval-reranking-and-multi-task-learning-for-knowledge-base-question-answering.pdf\",\n",
    "    \"https://assets.amazon.science/36/be/2669792342f2ba366ddca794069f/practiq-a-practical-conversational-text-to-sql-dataset-with-ambiguous-and-unanswerable-queries.pdf\",\n",
    "    \"https://assets.amazon.science/a7/7c/8bdade5c4eda9168f3dee6434fff/pc-amazon-frontier-model-safety-framework-2-7-final-2-9.pdf\"\n",
    "]\n",
    "\n",
    "# Define standard filenames to maintain consistency when loading data to Amazon S3\n",
    "filenames = [\n",
    "    \"retrieval-reranking-and-multi-task-learning-for-knowledge-base-question-answering.pdf\",\n",
    "    \"practiq-a-practical-conversational-text-to-sql-dataset-with-ambiguous-and-unanswerable-queries.pdf\",\n",
    "    \"pc-amazon-frontier-model-safety-framework-2-7-final-2-9.pdf\"\n",
    "]\n",
    "\n",
    "# Create a local temporary directory to store downloaded files before uploading to S3\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "\n",
    "# Define local directory path for storing downloaded files\n",
    "local_data_path = \"./data/\"\n",
    "\n",
    "# Download files from URLs and save them in the local directory\n",
    "for idx, url in enumerate(urls):\n",
    "    file_path = os.path.join(local_data_path, filenames[idx])\n",
    "    urlretrieve(url, file_path)\n",
    "\n",
    "# Define metadata corresponding to each document for indexing in the vector database\n",
    "metadata = [\n",
    "    {\n",
    "        \"metadataAttributes\": {\n",
    "            \"company\": \"Amazon\",\n",
    "            \"authors\": [\"Zhiguo Wang\", \"Patrick Ng\", \"Ramesh Nallapati\", \"Bing Xiang\"],\n",
    "            \"docType\": \"science\",\n",
    "            \"year\": 2021\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"metadataAttributes\": {\n",
    "            \"company\": \"Amazon\",\n",
    "            \"authors\": [\"Marvin Dong\", \"Nischal Ashok Kumar\", \"Yiqun Hu\", \"Anuj Chauhan\", \"Chung-Wei Hang\", \"Shuaichen Chang\", \n",
    "                        \"Lin Pan\", \"Wuwei Lan\", \"Henry Zhu\", \"Jiarong Jiang\", \"Patrick Ng\", \"Zhiguo Wang\"],\n",
    "            \"docType\": \"science\",\n",
    "            \"year\": 2025\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"metadataAttributes\": {\n",
    "            \"company\": \"Amazon\",\n",
    "            \"authors\": [\"Amazon\"],\n",
    "            \"docType\": \"science\",\n",
    "            \"year\": 2025\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Save metadata as JSON files alongside the corresponding documents\n",
    "for i, file in enumerate(filenames):\n",
    "    with open(f\"{local_data_path}{file}.metadata.json\", \"w\") as f:\n",
    "        json.dump(metadata[i], f)\n",
    "\n",
    "# Upload the directory to Amazon S3 under the 'pdf_documents' prefix\n",
    "upload_directory(local_data_path, s3_bucket_name, \"data/pdf_documents\")\n",
    "\n",
    "# Delete the local directory and its contents after upload to save space\n",
    "shutil.rmtree(local_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63ce136-960b-4848-8a68-bbcf45aa6a19",
   "metadata": {},
   "source": [
    "#### Amazon 10-K filings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24be2c40-eabc-4661-bf0f-6800cd38433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define URLs of Amazon's 10-K reports to be downloaded as example documents\n",
    "urls = [\n",
    "    \"https://d18rn0p25nwr6d.cloudfront.net/CIK-0001018724/e42c2068-bad5-4ab6-ae57-36ff8b2aeffd.pdf\",\n",
    "    \"https://d18rn0p25nwr6d.cloudfront.net/CIK-0001018724/c7c14359-36fa-40c3-b3ca-5bf7f3fa0b96.pdf\",\n",
    "    \"https://d18rn0p25nwr6d.cloudfront.net/CIK-0001018724/d2fde7ee-05f7-419d-9ce8-186de4c96e25.pdf\"\n",
    "]\n",
    "\n",
    "# Define standard filenames to maintain consistency when loading data to Amazon S3\n",
    "filenames = [\n",
    "    \"Amazon-10k-2025.pdf\",\n",
    "    \"Amazon-10k-2024.pdf\",\n",
    "    \"Amazon-10k-2023.pdf\"\n",
    "]\n",
    "\n",
    "# Create a local temporary directory to store downloaded files before uploading to S3\n",
    "local_data_path = \"./data/\"\n",
    "os.makedirs(local_data_path, exist_ok=True)\n",
    "\n",
    "# Download files from URLs and save them in the local directory\n",
    "for idx, url in enumerate(urls):\n",
    "    file_path = os.path.join(local_data_path, filenames[idx])\n",
    "    urlretrieve(url, file_path)\n",
    "\n",
    "# Define metadata corresponding to each document for indexing in the vector database\n",
    "metadata = [\n",
    "    {\n",
    "        \"metadataAttributes\": {\n",
    "            \"company\": \"Amazon\",\n",
    "            \"authors\": [\"Amazon\"],\n",
    "            \"docType\": \"10K Report\",\n",
    "            \"year\": 2025\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"metadataAttributes\": {\n",
    "            \"company\": \"Amazon\",\n",
    "            \"authors\": [\"Amazon\"],\n",
    "            \"docType\": \"10K Report\",\n",
    "            \"year\": 2024\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"metadataAttributes\": {\n",
    "            \"company\": \"Amazon\",\n",
    "            \"authors\": [\"Amazon\"],\n",
    "            \"docType\": \"10K Report\",\n",
    "            \"year\": 2023\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Save metadata as JSON files alongside the corresponding documents\n",
    "for i, file in enumerate(filenames):\n",
    "    metadata_file_path = os.path.join(local_data_path, f\"{file}.metadata.json\")\n",
    "    with open(metadata_file_path, \"w\") as f:\n",
    "        json.dump(metadata[i], f, indent=4)\n",
    "\n",
    "# Upload the directory to Amazon S3 under the 'pdf_documents' prefix\n",
    "upload_directory(local_data_path, s3_bucket_name, \"data/pdf_documents\")\n",
    "\n",
    "# Delete the local directory and its contents after upload to save space\n",
    "shutil.rmtree(local_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bac53a1-947e-41d9-9d41-15d75a4e2cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'677276078734-us-east-1-advanced-rag-workshop'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_bucket_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f37a302a-6716-46c1-9987-b8737656c273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the ground truth data to Amazon S3 under the 'ground_truth_data' prefix\n",
    "ground_truth_data_path = \"./ground_truth_data\"\n",
    "s3_key_prefix = \"data/ground_truth_data\"\n",
    "upload_directory(ground_truth_data_path, s3_bucket_name, s3_key_prefix)\n",
    "ground_truth_path = f\"s3://{s3_bucket_name}/{s3_key_prefix}/kbqa_questions_answers.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b7d891-3087-47f0-a89f-eacca3e89a59",
   "metadata": {},
   "source": [
    "#### 3.2 Metadata customization for CSV files\n",
    "The data is downloaded from [here](https://github.com/ali-ce/datasets) and it is licensed under [Creative Commons Attribution-ShareAlike 4.0 International license](https://github.com/ali-ce/datasets/blob/master/README.md#:~:text=Creative%20Commons%20Attribution%2DShareAlike%204.0%20International%20License.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87e32ceb-34e5-46de-9f5b-003f338825b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file downloaded successfully: ./videogame/video_games.csv\n",
      "JSON metadata file './videogame/video_games.metadata.json' has been generated.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import requests\n",
    "\n",
    "# Define a function to generate JSON metadata from a CSV file\n",
    "def generate_json_metadata(csv_file, content_fields, metadata_fields, excluded_fields):\n",
    "    \"\"\"\n",
    "    Generates a JSON metadata file for a given CSV file.\n",
    "\n",
    "    Parameters:\n",
    "        csv_file (str): Path to the CSV file.\n",
    "        content_fields (list): List of fields that contain document content.\n",
    "        metadata_fields (list): List of fields to include as metadata.\n",
    "        excluded_fields (list): List of fields to exclude (automatically populated if empty).\n",
    "\n",
    "    The function reads the CSV file, extracts headers, and structures metadata accordingly.\n",
    "    It then saves the metadata as a JSON file in the same directory as the CSV file.\n",
    "    \"\"\"\n",
    "    # Open the CSV file and read its headers\n",
    "    with open(csv_file, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        headers = reader.fieldnames  # Get column names\n",
    "\n",
    "    # Define JSON structure for metadata\n",
    "    json_data = {\n",
    "        \"metadataAttributes\": {},\n",
    "        \"documentStructureConfiguration\": {\n",
    "            \"type\": \"RECORD_BASED_STRUCTURE_METADATA\",\n",
    "            \"recordBasedStructureMetadata\": {\n",
    "                \"contentFields\": [{\"fieldName\": field} for field in content_fields],\n",
    "                \"metadataFieldsSpecification\": {\n",
    "                    \"fieldsToInclude\": [{\"fieldName\": field} for field in metadata_fields],\n",
    "                    \"fieldsToExclude\": []\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Determine fields to exclude (all fields not in content_fields or metadata_fields)\n",
    "    if not excluded_fields:\n",
    "        excluded_fields = set(headers) - set(content_fields + metadata_fields)\n",
    "\n",
    "    json_data[\"documentStructureConfiguration\"][\"recordBasedStructureMetadata\"][\"metadataFieldsSpecification\"][\"fieldsToExclude\"] = [\n",
    "        {\"fieldName\": field} for field in excluded_fields\n",
    "    ]\n",
    "\n",
    "    # Generate the output JSON file name\n",
    "    output_file = f\"{os.path.splitext(csv_file)[0]}.metadata.json\"\n",
    "\n",
    "    # Save metadata to a JSON file\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        json.dump(json_data, file, indent=4)\n",
    "\n",
    "    print(f\"JSON metadata file '{output_file}' has been generated.\")\n",
    "\n",
    "# Create a directory to store the video game CSV dataset\n",
    "local_dir = \"./videogame/\"\n",
    "os.makedirs(local_dir, exist_ok=True)\n",
    "\n",
    "# Define the URL of the dataset and the local file path\n",
    "csv_url = \"https://raw.githubusercontent.com/ali-ce/datasets/master/Most-Expensive-Things/Videogames.csv\"\n",
    "csv_file_path = os.path.join(local_dir, \"video_games.csv\")\n",
    "\n",
    "# Download the CSV file\n",
    "response = requests.get(csv_url, verify=False)  # `verify=False` ignores SSL certificate issues\n",
    "if response.status_code == 200:\n",
    "    with open(csv_file_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(f\"CSV file downloaded successfully: {csv_file_path}\")\n",
    "else:\n",
    "    print(\"Failed to download the CSV file.\")\n",
    "\n",
    "# Generate JSON metadata for the downloaded CSV file\n",
    "generate_json_metadata(\n",
    "    csv_file=csv_file_path,\n",
    "    content_fields=[\"Description\"],\n",
    "    metadata_fields=[\"Year\", \"Developer\", \"Publisher\"],\n",
    "    excluded_fields=[]  # Automatically determine excluded fields\n",
    ")\n",
    "\n",
    "# Upload directory containing the CSV and metadata JSON to S3\n",
    "upload_directory(local_dir, s3_bucket_name, \"data/csv\")\n",
    "\n",
    "# Remove the local directory after upload to save space\n",
    "shutil.rmtree(local_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39804c97-de8b-4ec5-99c5-e5afa076f649",
   "metadata": {},
   "source": [
    "### 4. Create a Vector Store using Amazon Open Search Serveless"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c7f5c7-71f3-4e80-9450-3c23be65cb8d",
   "metadata": {},
   "source": [
    "#### 4.1 Amazon OpenSearch Vector Collection  \n",
    "This will be used in Amazon Bedrock Knowledge Bases.  \n",
    "\n",
    "### **Code Steps:**  \n",
    "1. **Create security, network, and data access policies** within Amazon OpenSearch Serverless.  \n",
    "   - These will be assigned to the OpenSearch Vector Collection.  \n",
    "2. **Create an OpenSearch Serverless Vector Collection.**  \n",
    "3. **Retrieve the OpenSearch Serverless collection URL** for the Vector Collection created above.  \n",
    "4. **Wait for the Vector Collection** to reach the \"Ready\" state.  \n",
    "5. **Create an OpenSearch Serverless access policy** and attach it to the Bedrock execution role.\n",
    "\n",
    "\n",
    "> **Note**: This process will take approximately 4-5 minutes to complete. The system is creating security policies, network configurations, and a vector collection for storing embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75f54cc5-d1e0-4ce6-be05-f066fcc90911",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating OpenSearch Serverless vector collection. This process will take approximately 4-5 minutes...\n",
      "Encryption policy already exists or error: An error occurred (ConflictException) when calling the CreateSecurityPolicy operation: Policy with name advanced-rag-enc-policy2 and type encryption already exists\n",
      "Network policy already exists or error: An error occurred (ConflictException) when calling the CreateSecurityPolicy operation: Policy with name advanced-rag-network-policy2 and type network already exists\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/14/25 12:38:03] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> Couldn't call <span style=\"color: #008700; text-decoration-color: #008700\">'get_role'</span> to get Role ARN from role name                <a href=\"file:///Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages/sagemaker/session.py#5902\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5902</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         ravi.tiruvedula@fissionlabs.com to get Role path.                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/14/25 12:38:03]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m Couldn't call \u001b[38;2;0;135;0m'get_role'\u001b[0m to get Role ARN from role name                \u001b]8;id=107487;file:///Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=150096;file:///Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages/sagemaker/session.py#5902\u001b\\\u001b[2m5902\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         ravi.tiruvedula@fissionlabs.com to get Role path.                      \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access policy already exists or error: The current AWS identity is not a role: arn:aws:iam::677276078734:user/ravi.tiruvedula@fissionlabs.com, therefore it cannot be used as a SageMaker execution role\n",
      "Error: local variable 'encryption_policy' referenced before assignment\n",
      "Policies already exist or were not created properly.\n",
      "Collection 'advancedrag' already exists.\n",
      "Collection Host URL: e0ueyemy9ta6izbfugf7.us-east-1.aoss.amazonaws.com\n",
      "{'collectionDetails': [{'id': 'e0ueyemy9ta6izbfugf7', 'name': 'advancedrag', 'status': 'ACTIVE', 'type': 'VECTORSEARCH', 'arn': 'arn:aws:aoss:us-east-1:677276078734:collection/e0ueyemy9ta6izbfugf7', 'kmsKeyArn': 'auto', 'standbyReplicas': 'ENABLED', 'createdDate': 1744611639442, 'lastModifiedDate': 1744611662641, 'collectionEndpoint': 'https://e0ueyemy9ta6izbfugf7.us-east-1.aoss.amazonaws.com', 'dashboardEndpoint': 'https://e0ueyemy9ta6izbfugf7.us-east-1.aoss.amazonaws.com/_dashboards'}], 'collectionErrorDetails': [], 'ResponseMetadata': {'RequestId': 'f43e36a8-f8aa-4b5b-a6a6-a3cf6ba36336', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'f43e36a8-f8aa-4b5b-a6a6-a3cf6ba36336', 'date': 'Mon, 14 Apr 2025 07:08:03 GMT', 'content-type': 'application/x-amz-json-1.0', 'content-length': '499', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n",
      "\n",
      "Collection successfully created!\n",
      "Policy already exists or has been attached previously.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import time\n",
    "\n",
    "# Initialize the OpenSearch Serverless client\n",
    "aoss = boto3.client(\"opensearchserverless\", region_name=region_name)\n",
    "\n",
    "print(\"Creating OpenSearch Serverless vector collection. This process will take approximately 4-5 minutes...\")\n",
    "\n",
    "# Create security, network, and data access policies within OpenSearch Serverless (OSS)\n",
    "# These policies are essential for the correct access configuration of the OSS\n",
    "try:\n",
    "    result = bedrock_execution_iam_role.create_policies_in_oss(\n",
    "        vector_store_name=oss_vector_store_name,\n",
    "        aoss_client=aoss,\n",
    "        bedrock_kb_execution_role_arn=bedrock_kb_execution_role_arn\n",
    "    )\n",
    "    if result is not None:  # Check if the result is valid\n",
    "        encryption_policy, network_policy, access_policy = result\n",
    "    else:\n",
    "        print(\"Policies already exist or were not created properly.\")\n",
    "        encryption_policy = network_policy = access_policy = None\n",
    "except Exception as e:\n",
    "    print(f\"Error creating policies: {str(e)}\")\n",
    "    encryption_policy = network_policy = access_policy = None\n",
    "\n",
    "# Check if the collection already exists before creation\n",
    "try:\n",
    "    response = aoss.batch_get_collection(names=[oss_vector_store_name])\n",
    "    if response['collectionDetails']:\n",
    "        print(f\"Collection '{oss_vector_store_name}' already exists.\")\n",
    "        # Extract the collection ID from the existing collection\n",
    "        collection_id = response['collectionDetails'][0]['id']\n",
    "        host = f\"{collection_id}.{region_name}.aoss.amazonaws.com\"  # Construct the host URL\n",
    "        print(f\"Collection Host URL: {host}\")\n",
    "    else:\n",
    "        # Create an OpenSearch Serverless Vector Collection\n",
    "        collection = aoss.create_collection(name=oss_vector_store_name, type='VECTORSEARCH')\n",
    "        collection_id = collection['createCollectionDetail']['id']\n",
    "        host = f\"{collection_id}.{region_name}.aoss.amazonaws.com\"  # Construct the host URL\n",
    "        print(f\"Collection Host URL: {host}\")\n",
    "except Exception:\n",
    "    print(f\"Collection '{oss_vector_store_name}' already exists or could not be created.\")\n",
    "\n",
    "# Wait for collection creation to complete\n",
    "# The creation process can take a few minutes, so we check the status periodically\n",
    "response = aoss.batch_get_collection(names=[oss_vector_store_name])\n",
    "print(response)\n",
    "# Periodically check the collection's status until it's no longer 'CREATING'\n",
    "while response['collectionDetails'][0]['status'] == 'CREATING':\n",
    "    print('Collection is still being created...')\n",
    "    time.sleep(10)  # Sleep for 10 seconds before checking again\n",
    "    response = aoss.batch_get_collection(names=[oss_vector_store_name])\n",
    "\n",
    "# Confirm successful collection creation\n",
    "print('\\nCollection successfully created!')\n",
    "\n",
    "# Create the OpenSearch Serverless access policy and attach it to the Bedrock execution role\n",
    "# This ensures that the execution role has the correct permissions to access the collection\n",
    "try:\n",
    "    bedrock_execution_iam_role.create_oss_policy_attach_bedrock_execution_role(\n",
    "        collection_id=collection_id,\n",
    "        bedrock_kb_execution_role=bedrock_kb_execution_role\n",
    "    )\n",
    "    # Wait for the data access rules to be enforced (may take a minute)\n",
    "    time.sleep(10)\n",
    "except Exception:\n",
    "    print(\"Policy already exists or has been attached previously.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1d0dcd-8a40-4f1c-b8d7-633435a99573",
   "metadata": {},
   "source": [
    "#### 4.2 Create an index for the collection\n",
    "\n",
    "This index will be managed via Bedrock Knowledge Bases.\n",
    "\n",
    "**Code Steps:**\n",
    "\n",
    "1. **Create Index Body JSON**: Define the metadata or index structure that will be used for indexing in the OpenSearch Vector Collection.\n",
    "   \n",
    "2. **Create OpenSearch Object**: Instantiate an object of the `OpenSearch` class from the `opensearchpy` Python module. This object will be used to connect to the OpenSearch Vector Collection.\n",
    "\n",
    "3. **Create Index**: Using the OpenSearch object and the index body JSON, create the index in the OpenSearch Vector Collection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c013d7e6-faf3-42a7-92db-0cc1dabdc6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file:///Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages/botocore/credentials.py#1352\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1352</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=210843;file:///Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=458999;file:///Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages/botocore/credentials.py#1352\u001b\\\u001b[2m1352\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ws-index-fixed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/14/25 12:38:05] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> <span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">HEAD</span>                                                                       <a href=\"file:///Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages/opensearchpy/connection/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages/opensearchpy/connection/base.py#258\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">258</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://e0ueyemy9ta6izbfugf7.us-east-1.aoss.amazonaws.com:443/ws-index-fix</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">ed</span>                                                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/14/25 12:38:05]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m \u001b[1;38;2;215;175;0mHEAD\u001b[0m                                                                       \u001b]8;id=59352;file:///Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages/opensearchpy/connection/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=523610;file:///Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages/opensearchpy/connection/base.py#258\u001b\\\u001b[2m258\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://e0ueyemy9ta6izbfugf7.us-east-1.aoss.amazonaws.com:443/ws-index-fix\u001b[0m \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255med\u001b[0m                                                                         \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index \"ws-index-fixed\" already exists. Skipping creation.\n",
      "ws-index-hierarchical\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> <span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">HEAD</span>                                                                       <a href=\"file:///Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages/opensearchpy/connection/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages/opensearchpy/connection/base.py#258\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">258</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://e0ueyemy9ta6izbfugf7.us-east-1.aoss.amazonaws.com:443/ws-index-hie</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">rarchical</span>                                                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m \u001b[1;38;2;215;175;0mHEAD\u001b[0m                                                                       \u001b]8;id=186350;file:///Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages/opensearchpy/connection/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=656188;file:///Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages/opensearchpy/connection/base.py#258\u001b\\\u001b[2m258\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://e0ueyemy9ta6izbfugf7.us-east-1.aoss.amazonaws.com:443/ws-index-hie\u001b[0m \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mrarchical\u001b[0m                                                                  \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index \"ws-index-hierarchical\" already exists. Skipping creation.\n",
      "ws-index-semantic\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> <span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">HEAD</span>                                                                       <a href=\"file:///Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages/opensearchpy/connection/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages/opensearchpy/connection/base.py#258\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">258</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://e0ueyemy9ta6izbfugf7.us-east-1.aoss.amazonaws.com:443/ws-index-sem</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">antic</span>                                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m \u001b[1;38;2;215;175;0mHEAD\u001b[0m                                                                       \u001b]8;id=122287;file:///Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages/opensearchpy/connection/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=800052;file:///Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages/opensearchpy/connection/base.py#258\u001b\\\u001b[2m258\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://e0ueyemy9ta6izbfugf7.us-east-1.aoss.amazonaws.com:443/ws-index-sem\u001b[0m \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mantic\u001b[0m                                                                      \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index \"ws-index-semantic\" already exists. Skipping creation.\n",
      "ws-index-custom\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/14/25 12:38:06] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> <span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">HEAD</span>                                                                       <a href=\"file:///Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages/opensearchpy/connection/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages/opensearchpy/connection/base.py#258\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">258</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://e0ueyemy9ta6izbfugf7.us-east-1.aoss.amazonaws.com:443/ws-index-cus</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">tom</span>                                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/14/25 12:38:06]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m \u001b[1;38;2;215;175;0mHEAD\u001b[0m                                                                       \u001b]8;id=235238;file:///Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages/opensearchpy/connection/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=613317;file:///Users/fl_lpt-301/Documents/projects/crag/crag_ravi/CRAG/crag_env/lib/python3.10/site-packages/opensearchpy/connection/base.py#258\u001b\\\u001b[2m258\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://e0ueyemy9ta6izbfugf7.us-east-1.aoss.amazonaws.com:443/ws-index-cus\u001b[0m \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mtom\u001b[0m                                                                        \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index \"ws-index-custom\" already exists. Skipping creation.\n",
      "Index Creation Process Completed.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import boto3\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth, RequestError\n",
    "\n",
    "# Step 1: Set up AWS credentials for authentication with OpenSearch Service\n",
    "credentials = boto3.Session().get_credentials()  # Retrieves AWS credentials from the environment\n",
    "awsauth = AWSV4SignerAuth(credentials, region_name, \"aoss\")  # AWS authentication for OpenSearch\n",
    "\n",
    "# Define the base index name prefix\n",
    "oss_index_name = \"ws-index-\"\n",
    "\n",
    "# Step 2: Define the JSON body for index settings and mappings\n",
    "body_json = {\n",
    "   \"settings\": {\n",
    "      \"index.knn\": \"true\",  # Enable KNN (K-Nearest Neighbor) search\n",
    "       \"number_of_shards\": 1,  # Set the number of primary shards for the index\n",
    "       \"knn.algo_param.ef_search\": 512,  # KNN search efficiency parameter\n",
    "       \"number_of_replicas\": 0,  # Set the number of replicas to 0 (no redundancy)\n",
    "   },\n",
    "   \"mappings\": {\n",
    "      \"properties\": {\n",
    "         \"vector\": {\n",
    "            \"type\": \"knn_vector\",  # Define a KNN vector field for storing embeddings\n",
    "            \"dimension\": 1024,  # Set the vector's dimension to 1024\n",
    "             \"method\": {\n",
    "                 \"name\": \"hnsw\",  # Use the HNSW algorithm for KNN search\n",
    "                 \"engine\": \"faiss\",  # Use FAISS engine for efficient vector search\n",
    "                 \"space_type\": \"l2\"  # Use L2 (Euclidean) space for distance calculation\n",
    "             },\n",
    "         },\n",
    "         \"text\": {\n",
    "            \"type\": \"text\"  # Define a text field for storing unstructured text\n",
    "         },\n",
    "         \"text-metadata\": {\n",
    "            \"type\": \"text\"  # Define a text field for storing associated metadata\n",
    "        }\n",
    "      }\n",
    "   }\n",
    "}\n",
    "\n",
    "# Step 3: Build the OpenSearch client using AWS credentials and settings\n",
    "oss_client = OpenSearch(\n",
    "    hosts=[{'host': host, 'port': 443}],  # Provide OpenSearch host details\n",
    "    http_auth=awsauth,  # Use AWS authentication for API requests\n",
    "    use_ssl=True,  # Enable SSL for secure connection\n",
    "    verify_certs=True,  # Verify SSL certificates\n",
    "    connection_class=RequestsHttpConnection,  # Use RequestsHttpConnection for HTTP communication\n",
    "    timeout=300  # Set a timeout for the connection\n",
    ")\n",
    "\n",
    "# Step 4: Attempt to create multiple indices for different chunking strategies\n",
    "for strategy in [\"fixed\", \"hierarchical\", \"semantic\", \"custom\"]:\n",
    "    index_name = oss_index_name + strategy\n",
    "    print(index_name)\n",
    "    try:\n",
    "        # Check if the index already exists\n",
    "        if oss_client.indices.exists(index=index_name):\n",
    "            print(f'Index \"{index_name}\" already exists. Skipping creation.')  # CHANGED\n",
    "            continue\n",
    "        \n",
    "        # Create the index if it doesn't exist\n",
    "        oss_client.indices.create(index=index_name, body=json.dumps(body_json))\n",
    "        print(f'Creating Index: {index_name}...')  # Inform user about index creation\n",
    "    except RequestError as e:\n",
    "        print(f'Error while trying to create the index \"{index_name}\", with error {e.error}')  # CHANGED\n",
    "\n",
    "print('Index Creation Process Completed.')  # Inform user that the process is finished\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9da1be5-ae6d-4fcf-afe5-26c7fe6e7389",
   "metadata": {},
   "source": [
    "### Export variables to a file for the next lab\n",
    "\n",
    "> **Note**: We're saving all the important configuration variables to a JSON file so they can be easily accessed in subsequent notebooks. This ensures consistency and prevents the need to recreate these resources for each notebook in the workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac9231e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accountNumber': '677276078734', 'regionName': 'us-east-1', 'collectionArn': 'arn:aws:aoss:us-east-1:677276078734:collection/e0ueyemy9ta6izbfugf7', 'collectionId': 'e0ueyemy9ta6izbfugf7', 'vectorIndexName': 'ws-index-fixed', 'bedrockExecutionRoleArn': 'arn:aws:iam::677276078734:role/advanced-rag-workshop-bedrock_execution_role1-us-east-1', 's3Bucket': '677276078734-us-east-1-advanced-rag-workshop'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"variables.json\", \"w\") as f:\n",
    "    # Create a collection ARN using the standard format if needed\n",
    "    collection_arn = f\"arn:aws:aoss:{region_name}:{account_number}:collection/{collection_id}\"\n",
    "    print({\n",
    "            \"accountNumber\": account_number,\n",
    "            \"regionName\": region_name,\n",
    "            \"collectionArn\": collection_arn,\n",
    "            \"collectionId\": collection_id,\n",
    "            \"vectorIndexName\": oss_index_name+'fixed',\n",
    "            \"bedrockExecutionRoleArn\": bedrock_kb_execution_role_arn,\n",
    "            \"s3Bucket\": s3_bucket_name,\n",
    "            \"s3_ground_truth_path\": ground_truth_path\n",
    "        })\n",
    "    json.dump(\n",
    "        {\n",
    "            \"accountNumber\": account_number,\n",
    "            \"regionName\": region_name,\n",
    "            \"collectionArn\": collection_arn,\n",
    "            \"collectionId\": collection_id,\n",
    "            \"vectorIndexName\": oss_index_name+'fixed',\n",
    "            \"bedrockExecutionRoleArn\": bedrock_kb_execution_role_arn,\n",
    "            \"s3Bucket\": s3_bucket_name,\n",
    "            \"s3_ground_truth_path\": ground_truth_path\n",
    "        }, f, indent=4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afed8e3f-0c12-4896-9989-102b50f04ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76e6dc5-6a25-49d6-a97f-6dfdf20d7fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
